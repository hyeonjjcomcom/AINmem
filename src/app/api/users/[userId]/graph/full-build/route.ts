import { NextRequest, NextResponse } from 'next/server';
import {
  FolBuilder,
  GeminiAdapter,
  createFolClient
} from 'fol-sdk';
import mongoose from 'mongoose';
import connectDB from '@/lib/mongodb';
import { getFolStore } from '@/lib/folStore';
import ChatLog from '@/models/chatLogs';
import BuildHistory from '@/models/buildHistory';

/**
 * POST /api/users/[userId]/graph/full-build
 *
 * Full rebuild: ëª¨ë“  FOL ë°ì´í„° ì‚­ì œ í›„ ì „ì²´ ë©”ëª¨ë¦¬ ì¬ë¹Œë“œ
 *
 * ì²­í¬ ê¸°ë°˜ ë¹Œë“œ ì „ëµ:
 * 1. ê¸°ì¡´ FOL ë°ì´í„°(facts, constants, predicates) ì‚­ì œ
 * 2. ëª¨ë“  ë©”ëª¨ë¦¬ì˜ build_at ì´ˆê¸°í™”
 * 3. ì „ì²´ ë©”ëª¨ë¦¬ë¥¼ ë©”ì‹œì§€ 10ê°œ ë˜ëŠ” 10000 í† í° ë‹¨ìœ„ë¡œ ì²­í¬ë¥¼ ë§Œë“ ë‹¤
 * 4. ê° ì²­í¬ë¥¼ FOL buildí•˜ê³  ì €ì¥
 * 5. ì„±ê³µí•œ ì²­í¬ì˜ ë©”ëª¨ë¦¬ë“¤ë§Œ build_at ì—…ë°ì´íŠ¸ (_id ê¸°ë°˜)
 * 6. ì‹¤íŒ¨í•œ ì²­í¬ëŠ” build_atì´ ì—†ì–´ì„œ incremental buildì—ì„œ ìë™ ì¬ì²˜ë¦¬ë¨
 */

// í† í° ìˆ˜ ì¶”ì • í•¨ìˆ˜ (token_count í•„ë“œê°€ ì—†ì„ ê²½ìš° ì‚¬ìš©)
function estimateTokens(text: string): number {
  // ê°„ë‹¨í•œ ì¶”ì •: í‰ê· ì ìœ¼ë¡œ 1 í† í° â‰ˆ 4 ê¸€ì
  return Math.ceil(text.length / 4);
}

export async function POST(
  request: NextRequest,
  { params }: { params: Promise<{ userId: string }> }
) {
  try {
    await connectDB();
    const { userId } = await params;

    if (!userId) {
      return NextResponse.json(
        { success: false, error: 'userId is required' },
        { status: 400 }
      );
    }

    console.log('ğŸ”„ Starting full rebuild for user:', userId);

    // Step 1: ê¸°ì¡´ FOL ë°ì´í„° ì‚­ì œ
    const [factsResult, constantsResult, predicatesResult] = await Promise.all([
      mongoose.connection.collection('facts').deleteMany({ user_id: userId }),
      mongoose.connection.collection('constants').deleteMany({ user_id: userId }),
      mongoose.connection.collection('predicates').deleteMany({ user_id: userId })
    ]);

    console.log(`ğŸ—‘ï¸ Deleted: ${factsResult.deletedCount} facts, ${constantsResult.deletedCount} constants, ${predicatesResult.deletedCount} predicates`);

    // Step 2: ëª¨ë“  ë©”ëª¨ë¦¬ì˜ build_at ì´ˆê¸°í™”
    const resetResult = await ChatLog.updateMany(
      { user_id: userId },
      { $unset: { build_at: "" } }
    );
    console.log(`ğŸ”„ Reset build_at for ${resetResult.modifiedCount} memories`);

    // Step 3: ì „ì²´ ë©”ëª¨ë¦¬ ê°€ì ¸ì˜¤ê¸°
    const allMemories = await ChatLog.find({ user_id: userId }).sort({ createdAt: 1 }); // ì‹œê°„ìˆœ ì •ë ¬

    if (allMemories.length === 0) {
      console.log('ğŸ“Š No memories to build');
      return NextResponse.json({
        success: true,
        message: 'No memories to build',
        builtMemories: 0,
        deletedData: {
          facts: factsResult.deletedCount,
          constants: constantsResult.deletedCount,
          predicates: predicatesResult.deletedCount
        }
      });
    }

    console.log(`ğŸ“¦ Found ${allMemories.length} memories for full rebuild`);

    // Step 4: FOL ë¹Œë“œ ì„¤ì •
    const geminiApiKey = process.env.GEMINI_API_KEY;
    if (!geminiApiKey) {
      return NextResponse.json(
        { success: false, error: 'GEMINI_API_KEY not configured' },
        { status: 500 }
      );
    }

    const llmAdapter = new GeminiAdapter(geminiApiKey, 'gemini-2.5-pro');
    const store = getFolStore();
    const builder = new FolBuilder({ llm: llmAdapter });
    const client = createFolClient(builder, store);

    // Step 5: ì²­í¬ ê¸°ë°˜ ë¹Œë“œ
    const CHUNK_SIZE = 10; // ë©”ì‹œì§€ ê°œìˆ˜ ê¶Œì¥ì¹˜
    const PREFERRED_MAX_TOKENS = 10000; // ì„ í˜¸í•˜ëŠ” í† í° ìƒí•œ

    let totalBuiltMemories = 0;
    let chunkIndex = 0;

    for (let i = 0; i < allMemories.length; ) {
      chunkIndex++;
      let chunkMemories = [];
      let totalTokens = 0;

      // ìµœì†Œ 1ê°œ ë©”ì‹œì§€ëŠ” ë¬´ì¡°ê±´ í¬í•¨
      const firstMemory = allMemories[i];
      const firstTokens = firstMemory.token_count || estimateTokens(firstMemory.input_text);

      chunkMemories.push(firstMemory);
      totalTokens += firstTokens;
      i++;

      // ì¶”ê°€ ë©”ì‹œì§€ë“¤ì„ ì²­í¬ì— ì¶”ê°€
      while (i < allMemories.length && chunkMemories.length < CHUNK_SIZE) {
        const memory = allMemories[i];
        const memoryTokens = memory.token_count || estimateTokens(memory.input_text);

        // ë‹¤ìŒ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•˜ë©´ ì„ í˜¸ í† í°ì„ ì´ˆê³¼í•˜ëŠ” ê²½ìš°
        if (totalTokens + memoryTokens > PREFERRED_MAX_TOKENS) {
          break;
        }

        chunkMemories.push(memory);
        totalTokens += memoryTokens;
        i++;
      }

      console.log(`ğŸ“¦ Processing chunk ${chunkIndex}: ${chunkMemories.length} messages, ~${totalTokens} tokens`);

      const chunkIds = chunkMemories.map(m => m._id);
      const document = chunkMemories.map(m => m.input_text).join(' ').trim();
      const buildStartTime = Date.now();

      try {
        // ë¹Œë“œ ì „ FOL ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        const [constantsBeforeList, factsBeforeList, predicatesBeforeList] = await Promise.all([
          mongoose.connection.collection('constants').find({ user_id: userId }).project({ _id: 1 }).toArray(),
          mongoose.connection.collection('facts').find({ user_id: userId }).project({ _id: 1 }).toArray(),
          mongoose.connection.collection('predicates').find({ user_id: userId }).project({ _id: 1 }).toArray()
        ]);

        const constantIdsBefore = new Set(constantsBeforeList.map(c => c._id.toString()));
        const factIdsBefore = new Set(factsBeforeList.map(f => f._id.toString()));
        const predicateIdsBefore = new Set(predicatesBeforeList.map(p => p._id.toString()));

        // FOL ë¹Œë“œ ë° ì €ì¥
        await client.buildAndSave(document, userId);
        console.log(`âœ… Chunk ${chunkIndex} built successfully`);

        // ë¹Œë“œ í›„ FOL ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        const [constantsAfterList, factsAfterList, predicatesAfterList] = await Promise.all([
          mongoose.connection.collection('constants').find({ user_id: userId }).project({ _id: 1 }).toArray(),
          mongoose.connection.collection('facts').find({ user_id: userId }).project({ _id: 1 }).toArray(),
          mongoose.connection.collection('predicates').find({ user_id: userId }).project({ _id: 1 }).toArray()
        ]);

        // ìƒˆë¡œ ìƒì„±ëœ FOL ID í•„í„°ë§
        const newConstantIds = constantsAfterList
          .filter(c => !constantIdsBefore.has(c._id.toString()))
          .map(c => c._id);
        const newFactIds = factsAfterList
          .filter(f => !factIdsBefore.has(f._id.toString()))
          .map(f => f._id);
        const newPredicateIds = predicatesAfterList
          .filter(p => !predicateIdsBefore.has(p._id.toString()))
          .map(p => p._id);

        const buildDuration = Date.now() - buildStartTime;

        // BuildHistory ì €ì¥
        await BuildHistory.create({
          user_id: userId,
          chunk_index: chunkIndex,
          document,
          memory_ids: chunkIds,
          token_count: totalTokens,
          message_count: chunkMemories.length,
          build_type: 'full',
          status: 'success',
          generated_constants_count: newConstantIds.length,
          generated_facts_count: newFactIds.length,
          generated_predicates_count: newPredicateIds.length,
          generated_constant_ids: newConstantIds,
          generated_fact_ids: newFactIds,
          generated_predicate_ids: newPredicateIds,
          build_duration_ms: buildDuration
        });

        // ì„±ê³µí•œ ì²­í¬ì˜ ë©”ëª¨ë¦¬ë“¤ë§Œ build_at ì—…ë°ì´íŠ¸ (_id ê¸°ë°˜)
        const updateResult = await ChatLog.updateMany(
          { _id: { $in: chunkIds } },
          { $set: { build_at: new Date() } }
        );

        totalBuiltMemories += updateResult.modifiedCount;
        console.log(`âœ… Updated build_at for ${updateResult.modifiedCount} memories in chunk ${chunkIndex}`);
      } catch (chunkError: any) {
        console.error(`âŒ Error building chunk ${chunkIndex}:`, chunkError.message);

        // ì‹¤íŒ¨í•œ ì²­í¬ë„ BuildHistoryì— ê¸°ë¡
        try {
          await BuildHistory.create({
            user_id: userId,
            chunk_index: chunkIndex,
            document,
            memory_ids: chunkIds,
            token_count: totalTokens,
            message_count: chunkMemories.length,
            build_type: 'full',
            status: 'failed',
            error_message: chunkError.message,
            generated_constants_count: 0,
            generated_facts_count: 0,
            generated_predicates_count: 0,
            generated_constant_ids: [],
            generated_fact_ids: [],
            generated_predicate_ids: [],
            build_duration_ms: Date.now() - buildStartTime
          });
        } catch (historyError) {
          console.error(`âŒ Error saving build history for chunk ${chunkIndex}:`, historyError);
        }

        // ì‹¤íŒ¨í•œ ì²­í¬ëŠ” build_atì´ ì—†ìœ¼ë¯€ë¡œ incremental buildì—ì„œ ìë™ ì¬ì²˜ë¦¬ë¨
        console.log(`âš ï¸ Chunk ${chunkIndex} will be retried in incremental build`);
      }
    }

    return NextResponse.json({
      success: true,
      message: 'Full rebuild completed successfully',
      builtMemories: totalBuiltMemories,
      totalChunks: chunkIndex,
      deletedData: {
        facts: factsResult.deletedCount,
        constants: constantsResult.deletedCount,
        predicates: predicatesResult.deletedCount
      }
    });
  } catch (error: any) {
    console.error('âŒ Error in full rebuild:', error);
    return NextResponse.json(
      { success: false, error: error.message },
      { status: 500 }
    );
  }
}
